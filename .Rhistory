head(15) %>%
ggplot(aes(x = reorder(country, mean), y = mean)) +
geom_bar(stat = "identity", fill = 'steelblue') +  # Use a more visually appealing color
theme_minimal() +
labs(title = "Average in Time - Cosine Similarity",
subtitle = "Lowest 15 Countries by Average Similarity",
x = "Country",
y = "Cosine Similarity") +
ylim(0,0.5) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12))  # Adjust the text for better legibility
## export as pdf
ggsave("results/analysis/r1/cosine_similarity_15.eps", width = 5, height = 4)
## plot only lowest 15 averages
similarity.matrix.jaccard.df %>%
group_by(country) %>%
summarise(mean = mean(similarity, na.rm = TRUE)) %>%  # Make sure to remove NA values
arrange(mean) %>%
head(15) %>%
ggplot(aes(x = reorder(country, mean), y = mean)) +
geom_bar(stat = "identity", fill = '#EA922F') +  # Use a more visually appealing color
theme_minimal() +
labs(title = "Average in Time - Jaccard Similarity",
subtitle = "Lowest 15 Countries by Average Similarity",
x = "Country",
y = "Jaccard Similarity") +
ylim(0,1) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12))  # Adjust the text for better
## export as pdf
ggsave("results/analysis/r1/jaccard_similarity_15.eps", width = 5, height = 4)
## check how many countries are in common in the lowest 15 averages between cosine and jaccard:
similarity.matrix.cosine.df %>%
group_by(country) %>%
summarise(mean = mean(similarity)) %>%
arrange(mean) %>%
head(15) %>%
inner_join(similarity.matrix.jaccard.df %>%
group_by(country) %>%
summarise(mean = mean(similarity)) %>%
arrange(mean) %>%
head(15), by = "country")
### 11 countries
country.region <- mydata %>%
select(country, region) %>%
distinct()
country.continent <- mydata %>%
select(country, continent) %>%
distinct()
## check if these countries belong to the same region
similarity.matrix.cosine.df %>%
group_by(country) %>%
summarise(mean = mean(similarity)) %>%
arrange(mean) %>%
head(3) %>%  ## or tail
inner_join(., country.region, by = "country") %>%
select(country, region) %>%
distinct() %>%
count(region) %>%
arrange(desc(n))
## check if these countries belong to the same continent
similarity.matrix.cosine.df %>%
group_by(country) %>%
summarise(mean = mean(similarity)) %>%
arrange(mean) %>%
head(15) %>%
inner_join(., country.continent, by = "country") %>%
select(country, continent) %>%
distinct() %>%
count(continent) %>%
arrange(desc(n))
## check if these countries belong to the same region
similarity.matrix.jaccard.df %>%
group_by(country) %>%
summarise(mean = mean(similarity)) %>%
arrange(mean) %>%
head(15) %>%
inner_join(., country.region, by = "country") %>%
select(country, region) %>%
distinct() %>%
count(region) %>%
arrange(desc(n))
## check if these countries belong to the same continent
similarity.matrix.jaccard.df %>%
group_by(country) %>%
summarise(mean = mean(similarity)) %>%
arrange(mean) %>%
head(15) %>%
inner_join(., country.continent, by = "country") %>%
select(country, continent) %>%
distinct() %>%
count(continent) %>%
arrange(desc(n))
# Name: Guilherme Schultz Lindenmeyer
# Date: 10.11.2023
# Lecture: Programming Course for Economists
# Purpose: Do the second analysis of the project
# clean environment
rm(list = ls())
gc()
cat("\014")
## define the working directory
setwd("D:/GDrive/Faculdade/Mestrado/3.WS 2023/Lecture - Programming for Economists/Project")
getwd()
# relevant packages
packages <- c("tidyverse", "tm", "slam", "rvest", "xml2", "stringdist", "countrycode", "quanteda",
"SnowballC", "ggformula", "ggpubr", "scales", "readxl" , "stopwords", "wordcloud",
"syuzhet", "tidytext", "gridExtra", "ggstream")
# check if installed, otherwise, install, omit warnings
for(p in packages){
if(!require(p, character.only = TRUE)){
suppressMessages(suppressWarnings(install.packages(p)))
library(p, character.only = TRUE)
}
}
## let's do the second analysis:
## (2) Sentiment analysis of the speeches from each region over time. In question format:
## is there any difference between the sentiment of the speeches from each region?
## And is there any variation over time?
## for this, let's do the analysis for one continent then, once it's set up, we can do it for all of them
load("data/corpus/all.rda")
# Name: Guilherme Schultz Lindenmeyer
# Date: 10.11.2023
# Lecture: Programming Course for Economists
# Purpose: Do the second analysis of the project
# clean environment
rm(list = ls())
gc()
cat("\014")
## define the working directory
setwd("D:/GDrive/Faculdade/Mestrado/3.WS 2023/Lecture - Programming for Economists/Assignment")
getwd()
# relevant packages
packages <- c("tidyverse", "tm", "slam", "rvest", "xml2", "stringdist", "countrycode", "quanteda",
"SnowballC", "ggformula", "ggpubr", "scales", "readxl" , "stopwords", "wordcloud",
"syuzhet", "tidytext", "gridExtra", "ggstream")
# check if installed, otherwise, install, omit warnings
for(p in packages){
if(!require(p, character.only = TRUE)){
suppressMessages(suppressWarnings(install.packages(p)))
library(p, character.only = TRUE)
}
}
## let's do the second analysis:
## (2) Sentiment analysis of the speeches from each region over time. In question format:
## is there any difference between the sentiment of the speeches from each region?
## And is there any variation over time?
## for this, let's do the analysis for one continent then, once it's set up, we can do it for all of them
load("data/corpus/all.rda")
continents <- unique(mydata$continent)
years <- unique(mydata$year)
## let's do a dataframe. Columns: year, continent, anger, anticipation, disgust, fear, joy, sadness, surprise, trust, negative, positive
## rows: 50*5 = 250 rows
sentiment_matrix <- data.frame(matrix( ncol = 13))
colnames(sentiment_matrix) <- c("year", "continent", "anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust", "negative", "positive","total")
i <- 1
t <- years[1]
for(i in 1:length(continents)) {
for(t in years){
temp.data <- mydata %>% filter(continent == continents[i]) %>% filter(year == t)
## let's do the sentiment analysis
sentiment.df <- get_nrc_sentiment(temp.data$text)
## do a median aggregation
summ.sentiment.df <- sentiment.df %>% summarise_all(sum)
summ.sentiment.df$total <- sum(median.sentiment.df)
summ.sentiment.df$year <- t
summ.sentiment.df$continent <- continents[i]
sentiment_matrix <- rbind(sentiment_matrix, summ.sentiment.df)
}
}
# Name: Guilherme Schultz Lindenmeyer
# Date: 10.11.2023
# Lecture: Programming Course for Economists
# Purpose: Do the second analysis of the project
# clean environment
rm(list = ls())
gc()
cat("\014")
## define the working directory
setwd("D:/GDrive/Faculdade/Mestrado/3.WS 2023/Lecture - Programming for Economists/Assignment")
getwd()
# relevant packages
packages <- c("tidyverse", "tm", "slam", "rvest", "xml2", "stringdist", "countrycode", "quanteda",
"SnowballC", "ggformula", "ggpubr", "scales", "readxl" , "stopwords", "wordcloud",
"syuzhet", "tidytext", "gridExtra", "ggstream")
# check if installed, otherwise, install, omit warnings
for(p in packages){
if(!require(p, character.only = TRUE)){
suppressMessages(suppressWarnings(install.packages(p)))
library(p, character.only = TRUE)
}
}
## let's do the second analysis:
## (2) Sentiment analysis of the speeches from each region over time. In question format:
## is there any difference between the sentiment of the speeches from each region?
## And is there any variation over time?
## for this, let's do the analysis for one continent then, once it's set up, we can do it for all of them
load("data/corpus/all.rda")
continents <- unique(mydata$continent)
years <- unique(mydata$year)
## let's do a dataframe. Columns: year, continent, anger, anticipation, disgust, fear, joy, sadness, surprise, trust, negative, positive
## rows: 50*5 = 250 rows
sentiment_matrix <- data.frame(matrix( ncol = 13))
colnames(sentiment_matrix) <- c("year", "continent", "anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust", "negative", "positive","total")
i <- 1
t <- years[1]
for(i in 1:length(continents)) {
for(t in years){
temp.data <- mydata %>% filter(continent == continents[i]) %>% filter(year == t)
## let's do the sentiment analysis
sentiment.df <- get_nrc_sentiment(temp.data$text)
## do a median aggregation
summ.sentiment.df <- sentiment.df %>% summarise_all(sum)
summ.sentiment.df$total <- sum(summ.sentiment.df)
summ.sentiment.df$year <- t
summ.sentiment.df$continent <- continents[i]
sentiment_matrix <- rbind(sentiment_matrix, summ.sentiment.df)
}
}
rm(list = ls())
gc()
cat("\014")
## define the working directory
setwd("D:/GDrive/Faculdade/Mestrado/3.WS 2023/Lecture - Programming for Economists/Assignment")
getwd()
# relevant packages
packages <- c("tidyverse", "tm", "slam", "rvest", "xml2", "stringdist", "countrycode", "quanteda",
"SnowballC", "ggformula", "ggpubr", "scales", "readxl" , "stopwords", "wordcloud",
"syuzhet", "tidytext", "gridExtra", "ggstream")
# check if installed, otherwise, install, omit warnings
for(p in packages){
if(!require(p, character.only = TRUE)){
suppressMessages(suppressWarnings(install.packages(p)))
library(p, character.only = TRUE)
}
}
## set seed
set.seed(1000)
load("data/corpus/all.rda")
continents <- unique(mydata$continent)
years <- unique(mydata$year)
## let's do a dataframe. Columns: year, continent, anger, anticipation, disgust, fear, joy, sadness, surprise, trust, negative, positive
## rows: 50*5 = 250 rows
sentiment_matrix <- data.frame(matrix( ncol = 13))
colnames(sentiment_matrix) <- c("year", "continent", "anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust", "negative", "positive","total")
i <- 1
t <- years[1]
temp.data <- mydata %>% filter(continent == continents[i]) %>% filter(year == t)
## let's do the sentiment analysis
sentiment.df <- get_nrc_sentiment(temp.data$text)
summ.sentiment.df <- sentiment.df %>% summarise_all(sum)
summ.sentiment.df
summ.sentiment.df$total <- sum(summ.sentiment.df)
summ.sentiment.df$year <- t
summ.sentiment.df$continent <- continents[i]
summ.sentiment.df
sentiment_matrix <- data.frame(matrix( ncol = 13))
colnames(sentiment_matrix) <- c("year", "continent", "anger", "anticipation", "disgust", "fear", "joy", "sadness", "surprise", "trust", "negative", "positive","total")
i <- 1
t <- years[1]
for(i in 1:length(continents)) {
for(t in years){
temp.data <- mydata %>% filter(continent == continents[i]) %>% filter(year == t)
## let's do the sentiment analysis
sentiment.df <- get_nrc_sentiment(temp.data$text)
## do a median aggregation
summ.sentiment.df <- sentiment.df %>% summarise_all(sum)
summ.sentiment.df$total <- sum(summ.sentiment.df)
summ.sentiment.df$year <- t
summ.sentiment.df$continent <- continents[i]
sentiment_matrix <- rbind(sentiment_matrix, summ.sentiment.df)
}
}
## drop NA
sentiment_matrix <- sentiment_matrix %>% drop_na()
sentiment_matrix$year <- as.numeric(sentiment_matrix$year)
## let's save sentiment_matrix
save(sentiment_matrix, file = "data/sentiment_matrix.rda")
#clear
rm(list = ls())
load("data/sentiment_matrix.rda")
## now let's produce the loop
i <- continents[1]
## now let's produce the loop
continents <- unique(sentiment_matrix$continent)
i <- continents[1]
# Loop over each continent
for(i in continents) {
# Filter the data for the specified continent
continent_data <- subset(sentiment_matrix, continent == i)
# Drop continent column and total column
pos_neg_continent_data <- continent_data %>% select(year, positive, negative)
sentiment_continent_data <- continent_data %>% select(year, anger, anticipation, disgust, fear, joy, sadness, surprise, trust)
# Reshape the data into long format for plotting
pos_neg_continent_data <- reshape2::melt(pos_neg_continent_data, id.vars="year")
sentiment_continent_data <- reshape2::melt(sentiment_continent_data, id.vars="year")
# Define custom colors
cols8 <- hcl.colors(8, palette = "viridis", alpha = 0.8)
cols2 <- hcl.colors(2, palette = "Blue-Red 3", alpha = 0.7)
# Create the sentiment proportion plot
plot1 <- ggplot(sentiment_continent_data, aes(x = year, y = value, fill = variable)) +
geom_stream(type = "proportional") +
#geom_stream_label(aes(label = variable)) +
theme_minimal() +
labs(title = paste0("Sentiment for ", i),
x = "Year",
y = "Value") +
theme(plot.title = element_text(size = 14, face = "bold")) +
#theme(legend.position = "none") +
scale_fill_manual(values = cols8)
# Create the positive/negative proportion plot
plot2 <- ggplot(pos_neg_continent_data, aes(x = year, y = value, fill = variable)) +
geom_stream(type = "proportional") +
#geom_stream_label(aes(label = variable)) +
theme_minimal() +
labs(title = paste0("Aggregated for ", i),
x = "Year",
y = "Value") +
theme(plot.title = element_text(size = 14, face = "bold")) +
#theme(legend.position = "none") +
scale_fill_manual(values = cols2)
# Arrange the plots side by side
combined_plots <- grid.arrange(plot1, plot2, ncol = 2)
# Save the combined plots to files
path <- paste0("results/analysis/r2/", i, "_plots.pdf")
#path2 <- paste0("results/analysis/r2/", i, "_plots.eps")
ggsave(path, combined_plots, width = 8, height = 2.5)
#ggsave(path2, combined_plots, width = 7.5, height = 3)
}
# clean environment
rm(list = ls())
gc()
cat("\014")
## define the working directory
setwd("D:/GDrive/Faculdade/Mestrado/3.WS 2023/Lecture - Programming for Economists/Assignment")
getwd()
# relevant packages
packages <- c("tidyverse", "tm", "slam", "rvest", "xml2", "stringdist", "countrycode", "quanteda",
"SnowballC", "ggformula", "ggpubr", "scales", "readxl" , "stopwords", "wordcloud",
"syuzhet", "tidytext", "gridExtra", "ggstream", "topicmodels", "data.table", "seededlda")
# check if installed, otherwise, install, omit warnings
for(p in packages){
if(!require(p, character.only = TRUE)){
suppressMessages(suppressWarnings(install.packages(p)))
library(p, character.only = TRUE)
}
}
## set seed
set.seed(1000)
## since it's a topic analysis, let's use the stemmed corpus
load("data/corpus/stemmed/all_stemmed.rda")
continents <- unique(mydata$continent)
years <- unique(mydata$year)
corp2 <- corpus(
mydata,
docid_field = "doc_id",
text_field = "text",
meta = list(),
unique_docnames = TRUE)
toks <- tokens(corp2, remove_punct = TRUE, remove_symbols = TRUE, remove_number = TRUE)
# Apply stemming to the tokens
toks_stemmed <- tokens_wordstem(toks, language = "english")
dfmt <- dfm(toks_stemmed) %>%
dfm_remove(stopwords("en"), min_nchar = 2) %>%
dfm_trim(max_docfreq = 0.1, docfreq_type = "prop")
mdg_dict <- dictionary(list(
MDG1 = c("poverty", "hunger", "starvation", "malnutrition", "deprivation", "famine", "undernourished", "employment", "income", "indigence", "extreme poverty", "nutrition", "food security"),
MDG2 = c("education", "schooling", "literacy", "dropout", "teachers", "primary","access", "scholarship", "academia", "learning", "basic"),
MDG3 = c("gender", "equality", "empowerment", "women", "parity", "female", "girls", "discrimination", "equity", "gender disparity", "rights", "mainstreaming"),
MDG4 = c("child", "infant", "pediatric", "survival", "neonatal", "under-five", "kids"),
MDG5 = c("maternal", "maternity", "antenatal", "postnatal", "childbirth", "maternal mortality", "pregnancy", "birth", "reproductive health", "fertility", "midwifery", "motherhood", "care"),
MDG6 = c("disease", "HIV", "AIDS", "malaria", "tuberculosis", "epidemic", "healthcare", "vaccine", "virus", "infection", "disease","prevention", "HIV", "public", "malaria"),
MDG7 = c("environmental", "climate", "sustainability", "sanitation", "water", "renewable", "energy", "conservation", "biodiversity", "ecology", "natural", "resources", "clean","water", "sustainable", "development", "sanitation","access"),
MDG8 = c("global partnership", "trade", "economic","development", "aid", "debt", "technology","transfer", "financial","system", "LDCs", "landlocked", "states", "affordable", "private","sector", "information","technology"),
Conflict_and_War = c("war", "conflict", "military", "violence", "terrorism", "battle", "soldier", "weapons", "nuclear", "armament")
))
# Function to stem a vector of words
stem_words <- function(words) {
sapply(words, wordStem, language = "en")
}
# Apply the stem_words function to each element of the mdg_dict
mdg_dict_stemmed <- dictionary(lapply(mdg_dict, stem_words))
# View the stemmed dictionary
print(mdg_dict_stemmed)
## let's see how long it takes to run
start <- Sys.time()
lda_seed <- textmodel_seededlda(dfmt, mdg_dict_stemmed, residual = 2, auto_iter = T)
end <- Sys.time()
end - start
terms(lda_seed)
###
topic.dist <- data.frame(lda_seed$theta)
topic.dist$doc_id <- row.names(topic.dist)
all.topic.dist <- merge(topic.dist, mydata, by = "doc_id", suffixes = c("",""))
## save
save(all.topic.dist, file = "data/all.topic.dist.rda")
# load data
load("data/all.topic.dist.rda")
topic_matrix <- data.frame(matrix( ncol = 13))
colnames(topic_matrix) <- c("year", "continent", "MDG1", "MDG2", "MDG3", "MDG4", "MDG5", "MDG6",
"MDG7", "MDG8", "Conflict_and_War", "other1","other2")
continents <- all.topic.dist$continent %>% unique()
years <- all.topic.dist$year %>% unique()
i <- 1
t <- years[1]
for(i in 1:length(continents)) {
for(t in years){
temp.data <- all.topic.dist %>% filter(continent == continents[i]) %>% filter(year == t)
temp.data <- temp.data %>% select(colnames(topic_matrix))
## do a median aggregation
median.distribution.df <- temp.data %>% summarise_all(median)
topic_matrix <- rbind(topic_matrix, median.distribution.df)
}
}
## drop NA
topic_matrix <- topic_matrix %>% drop_na()
topic_matrix$year <- as.numeric(topic_matrix$year)
## let's save sentiment_matrix
save(topic_matrix, file = "data/topic_matrix.rda")
# List of continents including "ALL" for the combined plot
continents <- c("Africa", "Americas", "Asia", "Europe", "Oceania", "All")
i <- "All"
# List of continents including "ALL" for the combined plot
continents <- c("Africa", "Americas", "Asia", "Europe", "Oceania", "All")
i <- "All"
# Loop over each continent and "ALL"
for(i in continents) {
# Check if the current iteration is for all continents
if(i == "All") {
continent_data <- topic_matrix %>% select(-continent)
## let's do an average over the 5 continents
continent_data <- continent_data %>% group_by(year) %>% summarise_all(mean)
} else {
# Filter the data for the specified continent
continent_data <- subset(topic_matrix, continent == i)
}
# Select relevant columns and reshape data
if(i == "All"){
continent_data <- continent_data %>% select(-c(other1, other2))
} else {
continent_data <- continent_data %>% select(-c(continent, other1, other2))
}
continent_data <- reshape2::melt(continent_data, id.vars="year")
# Define nice colors
cols <- hcl.colors(9, palette = "Plasma", alpha = 0.8)
# Create the plot
plot <- ggplot(continent_data, aes(x = year, y = value, fill = variable)) +
geom_stream(type = "proportional") +
#geom_stream_label(aes(label = variable)) +
theme_minimal() +
labs(title = paste0("Topics for ", i),
x = "Year",
y = "Value") +
theme(plot.title = element_text(size = 14, face = "bold"))+
#legend.position = "none") +
scale_fill_manual(values = cols)
# Save the plot as a PDF
path <- paste0("results/analysis/r3/", i, "_plot.pdf")
ggsave(path, plot, width = 5.5, height = 3)
}
## let's import the world bank gdp growth data:
gdp_growth <- read.csv("data/worldbank/data_wb.csv", stringsAsFactors = F)
head(gdp_growth,5)
# let's write some NAs
gdp_growth <- gdp_growth %>%
mutate(across(starts_with("X"), ~na_if(.x, "..")))
# fix year columns
gdp_long <- gdp_growth %>%
gather(key = "year", value = "gdp_growth", starts_with("X")) %>%
mutate(
year = as.numeric(sub(".*\\.YR(\\d{4})\\.", "\\1", year)), # Extract the year from the column names
gdp_growth = as.numeric(gdp_growth) # Convert gdp_growth to numeric
) #%>%
# Select and rename the columns to match the desired format
panel_data <- gdp_long %>%
select(year, Country.Name, Country.Code, gdp_growth) %>%
rename(country = Country.Name, country_code = Country.Code)
panel_data$year <- as.character(panel_data$year)
str(all.topic.dist, 5)
merged_data <- merge(panel_data, all.topic.dist, by.x = c("year", "country_code"), by.y = c("year", "countrycode_fix"), all = TRUE)
## delete merged_data empty doc_id
merged_data <- merged_data %>% filter(!is.na(doc_id))
# save
save(merged_data, file = "data/regression_merged_data.rda")
merged_data$gdp_growth_rate <- merged_data$gdp_growth/100 + 1
## let's do some correlations
corr_matrix <- merged_data %>% select(MDG1, MDG2, MDG3, MDG4, MDG5, MDG6, MDG7, MDG8, Conflict_and_War, gdp_growth_rate) %>% cor(use  = "complete")
library(corrplot)
# plot correlation matrix
corrplot(corr_matrix, method = "color", type = 'lower',
col = colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))(200),
tl.col = "black", tl.srt = 45, tl.cex = 0.7)
# Add a title
title("Correlation Matrix")
library(fixest)
# let's transform variables in log
merged_data$log_gdp_growth <- log(merged_data$gdp_growth/100 + 1)
merged_data$log_MDG1 <- log(merged_data$MDG1 + 1)
merged_data$log_MDG2 <- log(merged_data$MDG2 + 1)
merged_data$log_MDG3 <- log(merged_data$MDG3 + 1)
merged_data$log_MDG4 <- log(merged_data$MDG4 + 1)
merged_data$log_MDG5 <- log(merged_data$MDG5 + 1)
merged_data$log_MDG6 <- log(merged_data$MDG6 + 1)
merged_data$log_MDG7 <- log(merged_data$MDG7 + 1)
merged_data$log_MDG8 <- log(merged_data$MDG8 + 1)
merged_data$log_Conflict_and_War <- log(merged_data$Conflict_and_War + 1)
model1 <- feols(log_gdp_growth ~ log_MDG1 + log_MDG2 + log_MDG3 + log_MDG4 + log_MDG5 + log_MDG6 + log_MDG7 + log_MDG8 + log_Conflict_and_War | year + continent, data = merged_data, cluster = "continent")
model2 <- feols(log_gdp_growth ~ log_MDG1 + log_MDG2 + log_MDG3 + log_MDG4 + log_MDG5 + log_MDG6 + log_MDG7 + log_MDG8 + log_Conflict_and_War | year^continent, data = merged_data, cluster = "continent")
model3 <- model1 <- feols(log_gdp_growth ~ log_MDG1 + log_MDG2 + log_MDG3 + log_MDG4 + log_MDG5 + log_MDG6 + log_MDG7 + log_MDG8 + log_Conflict_and_War | year^region, data = merged_data, cluster = "continent")
etable(model1, model2, model3, digits = 2, tex=T, se.below = FALSE)
